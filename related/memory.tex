\subsection{Memory} 

All other libraries, in some form, manage a stack or a ``tape''
to store the series of operations, and
the value and adjoints for each expression node.
Stan even writes their own custom memory allocator to create a memory pool,
which they refer to as the ``arena'', to alleviate memory fragmentation,
promote data locality, and reduce cost of memory allocations.
This is largely connected with their user interface.
A sequence of expressions to evaluate is represented 
in the usual way ending the statement with a semi-colon.
This forces the design to store a sequence of operations dynamically.
For some libraries, on top of memory management of these operations,
a run-time check must be performed at every evaluation to determine the correct operation~\cite{bell:2020}.
Others like Stan rely on dynamic polymorphism to look up the vtable for correct operation~\cite{carpenter:2015}.
FastAD is unique in that it overloads the comma operator to represent a sequence of expressions
(see Section~\ref{ssec:glue}), which completely eliminates the need for such memory management,
since the entire expression is known at compile-time.
Thanks to expression template, the sequence of operations to remember
is all stored within the type, which brings no memory cost during run-time.
This also significantly simplies the overall design.

While Stan notes that they are more memory-efficient than most libraries~\cite{carpenter:2015},
we noticed a non-negligible difference in memory consumption between Stan and FastAD.
We conducted a test to approximate the memory consumption of Stan's global stack object
and compare with the amount of memory consumed in FastAD code.

For Stan, we took the member variables
from the global stack object and computed the number of bytes used.
As noted in their paper~\cite{carpenter:2015}, these variables are responsible for storing
the operations, the pointers to the AD variables, and the raw bytes in the arena.
The global stack object can be accessed through \code{stan::math::ChainableStack::instance\_}.
The following is the pseudocode for how we computed the bytesizes for each member:
\begin{lstlisting}[style=customcpp]
var_stack_.size() * sizeof(element);
var_nochain_stack_.size() * sizeof(element);
var_alloc_stack_.size() * sizeof(element);
memalloc_.bytes_allocated();
\end{lstlisting}
where \code{sizeof(element)} refers to the number of bytes 
for the element type of the corresponding stack object.
We did not take into account other miscellaneous members for simplicity,
and this serves as a very rough lower bound on the total amount of memory allocated.

For FastAD, one can easily compute the memory consumption.
The only memory allocated is the value and adjoint cache,
the stack-allocated expression object,
and any heap-allocation that the expression object may make for special nodes
such as \code{for\_each, sum, prod} (iterator version).
Since we have \code{for\_each} in the example we tested, 
we add \code{K * sizeof(each expr)} where \code{each expr}
is the expression object generated by the lambda function argument to \code{for\_each}
and \code{K} is the number of iterations.
The following is the pseudocode for how we computed the bytesizes:
\begin{lstlisting}[style=customcpp]
val_buf.size() * sizeof(double); # value cache
adj_buf.size() * sizeof(double); # adjoint cache
sizeof(expr); # expression object
K * sizeof(each expr); # for_each heap-allocation
\end{lstlisting} 

We took the stochastic volatility example in Section~\ref{ssec:stochastic_volatility},
ran the same benchmark code for one iteration,
and after forward-evaluating, compute the total bytesize.
We computed for the usual range of $N$, but they each grew linearly as $N$ increased.
Hence, since it is enough to compare the slopes and 
we may take $N=0$ as $ 0$ total bytesize for both libraries,
we compare the bytesizes themselves at $N=2^{14}$, the last $N$.
The result for Stan is 4718696 bytes and FastAD is 1836216 bytes.
This rough estimate shows that FastAD uses at least 2.5 times less memory than STAN.
