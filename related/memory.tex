\subsection{Memory} 

All other libraries in some form manage a stack or a ``tape''
to store the series of operations, and
the value and adjoints for each expression node.
Stan even writes their own custom memory allocator to create a memory pool,
which they refer to as the ``arena'', to alleviate memory fragmentation
and promote data locality.

FastAD is unique in that it has no such memory management and
demonstrates that a simpler design without any fancy memory management 
performs much better in practice.
Because of expression template, the sequence of operations to remember
is all stored within the type information, which brings no memory cost during run-time.
This eliminates the need for the stack or the tape to store the operations directly.

The memory for value and adjoint for each expression node, as stated in previous sections,
is necessary by the very nature of the problem.
However, in Section~\ref{sssec:lazy-alloc}, we noted that FastAD
performs lazy allocation to allocate the exact number of elements needed.
We also saw in Section~\ref{ssec:eq} and~\ref{ssec:glue} that nodes can be further optimized
to not request any cache when they are not needed.
Stan's memory allocator allocates chunks of bytes at a time, doubling in size from the previous chunk.
While this is almost contiguous and can be reused during multiple AD evaluation,
it may certainly allocate more than necessary, especially if the chunk sizes are constantly doubled.

While Stan notes that they are more memory-efficient than most libraries~\cite{carpenter:2015},
we noticed a non-negligible difference in memory consumption from Stan and FastAD.
We conducted a test to approximate the memory consumption of Stan's global stack object
and compare with the amount of memory consumed in FastAD code.

For Stan, we took the member variables
from the global stack object and printed the number of bytes used 
(not necessarily the total allocated).
As noted in their paper, these variables are responsible for storing
the operations, the pointers to the AD variables, and the raw bytes in the arena.
The global stack object can be accessed through \code{stan::math::ChainableStack::instance\_}.
The following is the pseudocode for how we computed the bytesizes for each member:
\begin{lstlisting}[style=customcpp]
instance_->var_stack_.size() * sizeof(element);
instance_->var_nochain_stack_.size() * sizeof(element);
instance_->var_alloc_stack_.size() * sizeof(element);
instance_->memalloc_.bytes_allocated();
\end{lstlisting}
where \code{sizeof(element)} refers to the number of bytes 
for the element type of the corresponding \code{vector} object.
We did not take into account other miscellaneous vectors for simplicity,
and this serves as a very rough lower bound on the total amount of memory allocated.

For FastAD, one can easily compute the memory consumption.
The only memory allocated is the value and adjoint cache that get lazily allocated one-time,
and the stack-allocated expression object itself.
The expression object guarantees to not heap-allocate anything 
except for some special nodes such as \code{for\_each, sum, prod} (iterator version).
Since we have \code{for\_each} in the example we tested, 
we add \code{K * sizeof(each expr)} where \code{each expr}
is the expression object generated by the lambda function
and \code{K} is the number of iterations of the \code{for\_each}.
The following is the pseudocode for how we computed the bytesizes:
\begin{lstlisting}[style=customcpp]
val_buf.size() * sizeof(double); # value cache
adj_buf.size() * sizeof(double); # adjoint cache
sizeof(expr); # expression object
K * sizeof(each expr); # for-each heap-allocation
\end{lstlisting} 

We took the stochastic volatility example in Section~\ref{ssec:stochastic_volatility},
ran the same benchmark code but for one iteration,
and after forward-evaluating, print out the total bytesize.
We chose $N = 2^{14}$ for this test.
We computed for other $N$ as well, but they each grew linearly as $N$ increased,
so it is enough to compare the slopes, 
or simply the bytesizes themselves 
if we accept that $N=0$ leads to a total bytesize of $0$.
The total bytesize for Stan was 4718696 bytes and FastAD was 1836216 bytes.
This rough estimate shows that FastAD uses at least 2.5 times less memory than STAN.
